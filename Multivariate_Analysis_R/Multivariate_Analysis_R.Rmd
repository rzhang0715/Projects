---
title: "Final Project"
author: "Jitong Li, Ran Zhang"
date: "4/27/2019"
output: html_document
---

Read the data from excel files;
Set the working directory;
```{r}
setwd("~/Documents/course/Statistics/ST 537 (2019 Fall)/Project")
US_data <- read.csv("Data_US.csv",stringsAsFactors = FALSE)
World_data <- read.csv("Data_World.csv", stringsAsFactors = FALSE)
```

Data prep;
Check the data;
```{r}
str(US_data)
str(World_data)
```

Change the factor/characters to numeric for further processing;
```{r}
US_data$Workers <- as.numeric(US_data$Workers)
US_data$Customers <- as.numeric(US_data$Customers)
US_data$Community <- as.numeric(US_data$Community)
World_data$Workers <- as.numeric(World_data$Workers)
World_data$Customers <- as.numeric(World_data$Customers)
World_data$Community <- as.numeric(World_data$Community)
```

Remove the column of customers as so many NAs involved;
```{r}
US_data <- US_data[,c(1:6)]
World_data <- World_data[,c(1:6)]
```

Locating Missing values;
```{r}
US_data[!complete.cases(US_data),]
World_data[!complete.cases(World_data),]
```

Remove all missing value data;
```{r}
US_data <- US_data[complete.cases(US_data),]
World_data <- World_data[complete.cases(World_data),]
```

Re-index the data point;
```{r}
rownames(US_data) <- NULL
rownames(World_data) <- NULL
```

Check if any other NAs left;
```{r}
US_data[!complete.cases(US_data),]
World_data[!complete.cases(World_data),]
```

Check the index of the data;
```{r}
tail(US_data)
tail(World_data)
```

Subset the data with only multivariables;
```{r}
US_data_sub <- US_data[,3:6]
rownames(US_data_sub) <- US_data[,1]
World_data_sub <- World_data[,3:6]
rownames(World_data_sub) <- World_data[,1]
```

Check the normality of the each variable in US_Data with qq plot;
```{r}
par(mfrow=c(1,4))
for (ii in 1:4){
  qqnorm(US_data_sub[,ii],main=paste0("Q-Q plot of x", ii), pch=19, cex=1.5)
}
```

Check the normality of the US_data by mvn;
```{r}
library(MVN)
mvn((US_data_sub),mvnTest = "royston", multivariatePlot = "qq")
```
Comment: The US data is approximately normally with two outliers;

Check the normality of the each variable in World_Data with qq plot;
```{r}
for (ii in 1:4){
  qqnorm(World_data_sub[,ii],main=paste0("Q-Q plot of x", ii), pch=19, cex=1.5)
}
par(mfrow=c(1,1))
```

Identify and remove the two outliers by Mahalanobis distance;
US_data
```{r}
US_data_sub_cov <- cov(US_data_sub)
US_data_sub_cen <- scale(US_data_sub,center = T,scale = F)
US_data_sub_d2 <- diag(US_data_sub_cen%*%solve(US_data_sub_cov)%*%t(US_data_sub_cen))
```

Sort d2 in decreased way and find the most two biased outliers;
```{r}
head(sort(US_data_sub_d2,decreasing = T),2)
```
Comment: Sox Box and Patagonia are two outliers in US_data;

Removed outliers US data;
```{r}
US_data_sub_rm <- US_data_sub[-c(21,27), ]
```

Check the normality of the World_data by mvn;
```{r}
library(MVN)
mvn((World_data_sub),mvnTest = "royston", multivariatePlot = "qq")
```
Comment: The World data is approximately normally with two outliers;

World_data
```{r}
World_data_sub_cov <- cov(World_data_sub)
World_data_sub_cen <- scale(World_data_sub,center = T,scale = F)
World_data_sub_d2 <- diag(World_data_sub_cen%*%solve(World_data_sub_cov)%*%t(World_data_sub_cen))
```

Sort d2 in decreased way and find the most two biased outliers;
```{r}
head(sort(World_data_sub_d2,decreasing = T),2)
```
Comment: Someone Somewhere and MOVIN are two outliers in World_data;

Removed outliers World data;
```{r}
World_data_sub_rm <- World_data_sub[-c(23,28), ]
```

Standardized the standard deviation of the variables in US_data w/t removing outliers;
```{r}
US_data_sub_std <- scale(US_data_sub,center = T, scale = T)
apply(US_data_sub_std,2,sd)
```

Principal component analysis;
Perform the PCA on the US_data w/t removing outliers;
```{r}
US_data_sub_pca <- prcomp(US_data_sub_std)
summary(US_data_sub_pca)
US_data_sub_pca$rotation[,1:2]
```
Comment: Keep the first two PCs to achieve 70.5% variance; Keep the first three PCs to achieve 88.8% variance.


Standardized the standard deviation of the variables in US_data after removing outliers;
```{r}
US_data_sub_rm_std <- scale(US_data_sub_rm,center = T, scale = T)
apply(US_data_sub_rm_std,2,sd)
```

Perform the PCA on the US_data after removing outliers;
```{r}
US_data_sub_rm_pca <- prcomp(US_data_sub_rm_std)
summary(US_data_sub_rm_pca)
US_data_sub_rm_pca$rotation[,1:2]
```
Comment: Keep the first two PCs to achieve 70.0% variance; Keep the first three PCs to achieve 89.0% variance.

Standardized the standard deviation of the variables in World_data w/t removing outliers;
```{r}
World_data_sub_std <- scale(World_data_sub,center = T, scale = T)
apply(World_data_sub_std,2,sd)
```

Perform the PCA on the World_data w/t removing outliers;
```{r}
World_data_sub_std_pca <- prcomp(World_data_sub_std)
summary(World_data_sub_std_pca)
```
Comment: Keep the first two PCs to achieve 69.7% variance; Keep the first three PCs to achieve 90.7% variance.

Standardized the standard deviation of the variables in World_data after removing outliers;
```{r}
World_data_sub_rm_std <- scale(World_data_sub_rm,center = T, scale = T)
apply(World_data_sub_rm_std,2,sd)
```

Perform the PCA on the World_data after removing outliers;
```{r}
World_data_sub_rm_std_pca <- prcomp(World_data_sub_rm_std)
summary(World_data_sub_rm_std_pca)
World_data_sub_rm_pca$rotation[,1:2]
```
Comment: Keep the first two PCs to achieve 70.9& variance; Keep first three variance to achieve 92.6% variance.

Factor analysis (MLE default);
Perform the factor analysis on the US_data w/t removing outliers;
```{r}
US_data_sub_fa <- factanal(US_data_sub,factors = 1)
US_data_sub_fa
```

Perform the factor analysis on the US_data after removing outliers;
US_data_sub
```{r}
US_data_sub_rm_fa <- factanal(US_data_sub_rm,factors = 1)
US_data_sub_rm_fa
```

Perform the factor analysis on the World_data w/t removing outliers;
```{r}
World_data_sub_fa <- factanal(World_data_sub,factors = 1)
World_data_sub_fa
```

Perform the factor analysis on the World_data after removing outliers;
```{r}
World_data_sub_rm_fa <- factanal(World_data_sub_rm,factors = 1)
World_data_sub_rm_fa
```
Comment: One factor is not enough for world_data w/t removing outliers; but enough for it after romving outliers.

Normality test;
Test in US_data;
```{r}
par(mfrow=c(1,5))
for (ii in 2:6){
  qqnorm(US_data[,ii],main=paste0("Q-Q plot of x", ii), pch=19, cex=1.5)
}
par(mfrow=c(1,1))
```

Test all variables together;
```{r}
mvn((US_data[,2:6]),mvnTest = "royston", multivariatePlot = "qq")
```

Identify the outliers by manalonis distance;
```{r}
US_data_cov <- cov(US_data[,2:6])
US_data_cen <- scale(US_data[,2:6],center = T,scale = F)
US_data_d2 <- diag(US_data_cen%*%solve(US_data_cov)%*%t(US_data_cen))
US_data_d2 <- matrix(US_data_d2,ncol = 1)
rownames(US_data_d2) <- US_data[,1]
rownames(US_data_d2) <- NULL
```

Sort the distance in decreasing direction and identify the most three outliers;
```{r}
head(sort(US_data_d2,decreasing = T),4)
```


Test each variable individually of world data;
```{r}
par(mfrow=c(1,5))
for (ii in 2:6){
  qqnorm(World_data[,ii],main=paste0("Q-Q plot of x", ii), pch=19, cex=1.5)
}
par(mfrow=c(1,1))
```
Test all variables together;
```{r}
mvn((World_data[,2:6]),mvnTest = "royston", multivariatePlot = "qq")
```
Identify the outliers by manalonis distance;
```{r}
World_data_cov <- cov(World_data[,2:6])
World_data_cen <- scale(World_data[,2:6],center = T,scale = F)
World_data_d2 <- diag(World_data_cen%*%solve(World_data_cov)%*%t(World_data_cen))
World_data_d2 <- matrix(World_data_d2,ncol = 1)
rownames(World_data_d2) <- World_data[,1]
```
Sort the distance in decreasing direction and identify the most three outliers;
```{r}
head(sort(World_data_d2,decreasing = T),3)
```



Two-sample Hotelling's T^2 test w/t removing outliers;
```{r}
library(ICSNP)
HotellingsT2(US_data[,2:6], World_data[,2:6])
```


Two-sample Hotelling's T^2 test after removing outliers;
```{r}
US_data_rm <- US_data[-c(13,21,27,33),]
World_data_rm <- World_data[-c(7,23,28),]
HotellingsT2(US_data_rm[,2:6], World_data_rm[,2:6])
```


Combine the US_data and world_data;
Set the new column as region; (region = 1 represents US, region = 0 represetns world_data)
```{r}
# Set the US_data and add a column named region with all 1;
US_column <- matrix(rep(1,33),ncol = 1)
colnames(US_column) <- "Region"
rownames(US_column) <- US_data[,1]
US_data_new <- cbind(US_data, US_column) 
head(US_data_new)

# Set the World_data as the same as the US_data but with 0;
World_column <- matrix(rep(0,36),ncol = 1)
colnames(World_column) <- "Region"
rownames(World_column) <- World_data[,1]
World_data_new <- cbind(World_data, World_column) 
head(World_data_new)

# Combine the two data as total data;
Total_data <- rbind(US_data_new, World_data_new)
Total_data_rm <- rbind(US_data_rm, World_data_rm)
```

Test all components contribute equally to the performance of US_data;
```{r}
# Build the contrast matrix to test eqaulity;
# To test mu1 = mu2 = mu3 =mu4;
contrast_matrix <-matrix(c(1,-1,0,0,1,0,-1,0,1,0,0,-1),nrow=3,byrow = T)
rownames(contrast_matrix) <- c("Difference between Governance and Workers",
                               "Difference between Governance and Community",
                               "Difference between Governance and Environment")
contrast_matrix
# Build the function to test contrasts;
Data_contrast <- function(data_matrix_sub,contrast_matrix,alpha=0.05) {
  #Input arguments
  # data matrix, contrast matrix and alpha
  dat <- data_matrix_sub
  C <- contrast_matrix
  
  # Sample mean vector
  xbar <- colMeans(dat)
  # Sample covariance matrix
  S <- cov(dat)
  
  # Parameters
  n <- nrow(dat)
  q <- nrow(C)
  
  # Intermediate quantities
  invCSC <- solve(C%*% S %*% (t(C)))
  Cxbar <- C %*% xbar
  # Test statistic
  data_test <- n*(n-q)/((n-1)*q)*(t(Cxbar)) %*% invCSC %*% (Cxbar)
  # Critical value
  critical_value_F = qf(p=0.05, df1=q, df2=n-q, lower.tail = F)
  # P-value
  pv <- pf(data_test, df1=q, df2=n-q,lower.tail = F)
  
  # Display the resutls
  test_statistics <- data.frame(data_test_statistics= data_test, critical = critical_value_F, df1=q, df2=n-q,
                                pvalue=pv)
  # std errors
  sdvec <- sqrt(diag(invCSC)/n)
  # Intervals with point estimates
  confidence_interval <- data.frame(Estimate=Cxbar, Lower=Cxbar-critical_value_F*sdvec,
                                    Upper=Cxbar + critical_value_F*sdvec)
  return(list(Test_statistics = test_statistics,Confidence_interval = confidence_interval))
}
# Test for equality of the variables in US data;
# Test specific differences by simultaneously confidence interval in US data;
Data_contrast(US_data_sub,contrast_matrix)

# Test for equality of the variables in World data;
# Test specific differences by simultaneously confidence interval in World data;
Data_contrast(World_data_sub,contrast_matrix)
```


Regression tree;
```{r}
library(rpart)
library(rattle)
# Draw the tree of US_data;
tree <- rpart(Overall~Governance+Workers+Community+Environment, data=US_data)
fancyRpartPlot(tree,sub="", main="Classification of the US_Data")

# Draw the tree of World_data;
tree2 <- rpart(Overall~Governance+Workers+Community+Environment, data=World_data)
fancyRpartPlot(tree2,sub="", main="Classification of the World_Data")

# Draw the tree of All_data;
tree3 <- rpart(Overall~Governance+Workers+Community+Environment, data=Total_data)
fancyRpartPlot(tree3,sub="", main="Classification of the Total_Data")
# Draw the tree of All_data after removing outliers;
tree4 <- rpart(Overall~Governance+Workers+Community+Environment, data=Total_data_rm)
fancyRpartPlot(tree4,sub="", main="Classification of the Total_Data w/t outliers")
```





